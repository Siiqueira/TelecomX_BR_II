# ğŸ›°ï¸ Projeto: PrevisÃ£o de Cancelamento de Clientes (Churn) - TelecomX_BR

## ğŸ¯ MissÃ£o do Cientista de Dados
Desenvolver um pipeline de machine learning completo para prever a evasÃ£o (churn) de clientes da TelecomX_BR, permitindo aÃ§Ãµes proativas de retenÃ§Ã£o por parte da empresa.

---

## ğŸ“Œ Objetivos do Desafio

- Preparar os dados para modelagem (tratamento, encoding, balanceamento);
- Analisar a correlaÃ§Ã£o entre variÃ¡veis e selecionar as mais relevantes;
- Treinar e comparar diferentes modelos preditivos;
- Avaliar o desempenho com mÃ©tricas robustas;
- Interpretar resultados com foco estratÃ©gico em retenÃ§Ã£o;
- Gerar relatÃ³rio tÃ©cnico completo para stakeholders;
- Salvar modelo final com pipeline e encoding embutidos.

---

## ğŸ“ Estrutura do Projeto

```bash
ğŸ“¦ projeto_churn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Dados brutos
â”‚   â”œâ”€â”€ processed/                   # Dados tratados
â”‚   â””â”€â”€ results/                     # CSVs e grÃ¡ficos gerados
â”œâ”€â”€ models/
â”‚   â””â”€â”€ modelo_final.pkl             # Modelo final salvo
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ modelo_churn.ipynb          # Notebook principal do projeto
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipeline/                    # FunÃ§Ãµes para o pipeline e modelagem
â”œâ”€â”€ README.md
â”œâ”€â”€ Relatorio_Tecnico.md
â””â”€â”€ Arquitetura_Projeto.md
```


## âš™ï¸ Tecnologias e Bibliotecas Utilizadas

| Categoria              | Bibliotecas                                                     |
|-----------------------|----------------------------------------------------------------|
| ManipulaÃ§Ã£o de dados   | pandas, numpy                                                  |
| VisualizaÃ§Ã£o          | matplotlib, seaborn                                            |
| Modelagem             | scikit-learn, imbalanced-learn                                 |
| AvaliaÃ§Ã£o de modelos  | classification_report, roc_auc_score, confusion_matrix, precision_recall_curve, learning_curve |
| Pipeline e HiperparÃ¢metros | Pipeline, RandomizedSearchCV, GridSearchCV                |
| SerializaÃ§Ã£o          | pickle                                                        |
| Outros                | warnings, StratifiedKFold                                      |

---

## ğŸ“ˆ Modelo Final

| Item                     | DescriÃ§Ã£o                                                   |
|--------------------------|-------------------------------------------------------------|
| Modelo escolhido         | Random Forest Classifier                                    |
| TÃ©cnica de balanceamento  | Oversampling (SMOTE)                                        |
| Top Features             | tempo_contrato_Mensal, permanencia, fibra_optica, total_gastos, pagamento_Cheque_Digital |
| Accuracy final           | 0.77                                                        |
| Recall (classe 1 - churn)| 0.78                                                        |
| F1-score (classe 1)      | 0.62                                                        |
| ROC AUC                  | 0.82                                                        |

---

## ğŸ§ª Teste com Dados de ValidaÃ§Ã£o

| Classe | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| 0      | 0.93      | 0.81   | 0.87     | 16      |
| 1      | 0.57      | 0.80   | 0.67     | 5       |
| **AcurÃ¡cia** |       |        | **0.81** | **21**  |

âš ï¸ O conjunto de validaÃ§Ã£o possui apenas 21 amostras, portanto os resultados devem ser interpretados com cautela.

---

## ğŸ§  ConclusÃ£o EstratÃ©gica

Clientes com contratos mensais, baixa permanÃªncia, e que utilizam fibra Ã³ptica representam o maior risco de churn.

EstratÃ©gias de retenÃ§Ã£o ativa devem focar nesses perfis.

O modelo, mesmo diante de dados desbalanceados, apresenta capacidade robusta de generalizaÃ§Ã£o e Ã© adequado para uso em produÃ§Ã£o.

---

## ğŸ“Œ ObservaÃ§Ãµes

Este projeto Ã© voltado para anÃ¡lise de churn com dados sintÃ©ticos e objetivos didÃ¡ticos.

Para implementaÃ§Ã£o em produÃ§Ã£o, recomenda-se:

- Monitoramento contÃ­nuo de mÃ©tricas;
- Coleta de novas variÃ¡veis comportamentais;
- AtualizaÃ§Ã£o periÃ³dica do modelo.

---

## ğŸ“¬ Contato

Para dÃºvidas, sugestÃµes ou colaboraÃ§Ãµes, entre em contato com o time de ciÃªncia de dados da TelecomX_BR.

---

## âœ… Modelos Testados

| Modelo                    | AUC     | Recall Classe 1 | F1 Classe 1 | Accuracy |
|--------------------------|---------|------------------|-------------|----------|
| Decision Tree            | 0.73    | 0.69             | 0.57        | 0.72     |
| Random Forest            | 0.82    | 0.71             | 0.61        | 0.76     |
| Random Forest + SMOTE    | 0.82    | 0.78             | 0.62        | 0.74     |

---

## â­ Modelo Final Escolhido: `RandomForestClassifier` com Oversampling (SMOTE)

```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
## Tuning com RandomizedSearchCV

- Melhor desempenho em recall da classe positiva (cancelamento)
- Selecionadas as 5 features mais relevantes

### ğŸ“Š Desempenho Final

**Teste com Dados de ValidaÃ§Ã£o**

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0      | 0.93      | 0.81   | 0.87     | 16      |
| 1      | 0.57      | 0.80   | 0.67     | 5       |

- **AcurÃ¡cia Geral:** 81%  
- **Weighted F1-score:** 0.82

### ğŸ—‚ï¸ Links Importantes

- ğŸ“ˆ GrÃ¡ficos de correlaÃ§Ã£o e distribuiÃ§Ã£o  
- ğŸ“Š Matriz de confusÃ£o  
- ğŸ“Š Curva ROC AUC  
- ğŸ“Š Curva PrecisÃ£o x Recall  
- ğŸ“Š Features Importances (CSV + grÃ¡fico)  
- ğŸ“Š Resultados de validaÃ§Ã£o cruzada  
- ğŸ“Š ComparaÃ§Ãµes entre modelos  


ğŸ“¦ Como Usar

Clone o repositÃ³rio:

git clone https://github.com/seuusuario/telecom_churn_prediction.git


Instale as dependÃªncias:

pip install -r requirements.txt


Execute os notebooks disponÃ­veis na pasta notebooks/.

Avalie o modelo final ou carregue o modelo .pkl com o seguinte cÃ³digo:

import pickle
with open('models/modelo_final.pkl', 'rb') as f:
    model = pickle.load(f)

ğŸ§  ConclusÃ£o

Este projeto entregou uma soluÃ§Ã£o preditiva eficiente para o problema de churn, com foco em clientes com maior risco de cancelamento, variÃ¡veis mais influentes e estratÃ©gias prÃ¡ticas de retenÃ§Ã£o. O modelo Random Forest com SMOTE demonstrou robustez, generalizaÃ§Ã£o e capacidade de auxiliar a empresa na tomada de decisÃµes estratÃ©gicas.

ğŸ“® Contato

ğŸ‘¨â€ğŸ’» Desenvolvido por: [Seu Nome]
ğŸ“§ Email: seu.email@dominio.com
ğŸ”— LinkedIn: linkedin.com/in/seu-perfil

--- 
Relatorio_Tecnico.md

# ğŸ“Š RelatÃ³rio TÃ©cnico â€“ AnÃ¡lise do Modelo de PrevisÃ£o de EvasÃ£o de Clientes (Churn)

---

## ğŸ“Œ SumÃ¡rio

1. [Carregamento e Tratamento dos Dados](#1-carregamento-e-tratamento-dos-dados)
2. [AnÃ¡lise ExploratÃ³ria e CorrelaÃ§Ãµes](#2-anÃ¡lise-exploratÃ³ria-e-correlaÃ§Ãµes)
3. [Modelagem Inicial](#3-modelagem-inicial)
4. [AvaliaÃ§Ã£o dos Modelos](#4-avaliaÃ§Ã£o-dos-modelos)
5. [Balanceamento dos Dados](#5-balanceamento-dos-dados)
6. [Modelo Final â€“ Ajuste de HiperparÃ¢metros](#6-modelo-final--ajuste-de-hiperparÃ¢metros)
7. [Teste com Dados de ValidaÃ§Ã£o](#7-teste-com-dados-de-validaÃ§Ã£o)
8. [ConclusÃ£o EstratÃ©gica](#8-conclusÃ£o-estratÃ©gica)

---

## 1. Carregamento e Tratamento dos Dados

Os dados foram carregados e tratados com as seguintes aÃ§Ãµes:

- RemoÃ§Ã£o de colunas irrelevantes
- TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas com One Hot Encoding
- AnÃ¡lise de proporÃ§Ã£o da variÃ¡vel alvo (target)

### ProporÃ§Ã£o do Target (Cancelamento):

- **NÃ£o Cancelaram (classe 0):** 73%
- **Cancelaram (classe 1):** 27%

ğŸ” *Os dados estÃ£o desbalanceados. Isso pode causar viÃ©s nos modelos preditivos. TÃ©cnicas de oversampling e undersampling foram testadas para mitigar esse problema.*

---

## 2. AnÃ¡lise ExploratÃ³ria e CorrelaÃ§Ãµes

### Principais descobertas:

- **Gastos Mensais** e **Gastos DiÃ¡rios** tÃªm **correlaÃ§Ã£o perfeita**. Decidimos remover `gastos_mensais`.
- Contrato Mensal tem forte correlaÃ§Ã£o com cancelamento (**+40%**).
- Clientes com maior permanÃªncia tÃªm menor chance de cancelar (**correlaÃ§Ã£o negativa de -35%**).
- Fibra Ã“ptica estÃ¡ correlacionada com gastos elevados e maior taxa de churn.
- Clientes com contratos mais curtos tendem a acumular menos gastos e cancelar mais cedo.

ğŸ“ˆ **Links para grÃ¡ficos:**
- [ğŸ”— GrÃ¡fico de CorrelaÃ§Ã£o](#coloque-aqui-seu-link)
- [ğŸ”— Tempo de Contrato x Cancelamento](#coloque-aqui-seu-link)
- [ğŸ”— Total de Gasto x Cancelamento](#coloque-aqui-seu-link)

---

## 3. Modelagem Inicial

### SeparaÃ§Ã£o dos dados:

- **Dados de treino:** (5608, 26)
- **Dados de teste:** (1403, 26)

### Modelos testados:

1. **Decision Tree Classifier**
```python
DecisionTreeClassifier(
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
## 4. AvaliaÃ§Ã£o dos Modelos

### ğŸ”¢ MÃ©tricas Comparativas

| Modelo         | AUC  | Recall (Classe 1) | F1 (Classe 1) | Accuracy |
|----------------|------|-------------------|---------------|----------|
| Decision Tree  | 0.73 | 0.69              | 0.57          | 0.72     |
| Random Forest  | 0.82 | 0.71              | 0.61          | 0.76     |

### ğŸ“‰ Matriz de ConfusÃ£o

ğŸ”— [Link para o grÃ¡fico]

> Random Forest foi superior em quase todas as mÃ©tricas, principalmente na identificaÃ§Ã£o correta de clientes que nÃ£o cancelam (classe 0).  
> A classe 1 (cancelamento) ainda apresenta desafios.

### ğŸ“ˆ Curva ROC AUC

ğŸ”— [Link para o grÃ¡fico]

- Decision Tree: AUC = 0.73  
- Random Forest: AUC = 0.82

### ğŸ“ˆ Curva PrecisÃ£o x Recall

ğŸ”— [Link para o grÃ¡fico]

- Decision Tree: Avg. Precision = 0.44  
- Random Forest: Avg. Precision = 0.59

### ğŸ“„ Classification Report

ğŸ”— [Link para CSV com os relatÃ³rios]

> Random Forest teve melhor desempenho para a classe de interesse (churn).  
> F1-Score e recall da classe 1 foram superiores ao Decision Tree.

### ğŸ” ValidaÃ§Ã£o Cruzada

ğŸ”— [Link para CSV]

> Resultados mais estÃ¡veis e consistentes com Random Forest.  
> Menor variÃ¢ncia e melhor generalizaÃ§Ã£o.

---

## 5. Balanceamento dos Dados

**TÃ©cnicas utilizadas:**

- Oversampling (SMOTE) âœ… escolhido  
- Undersampling (NearMiss)

ğŸ“„ ğŸ”— [CSV com resultados]

**Escolha: Oversampling com SMOTE**  
âœ… Apresentou melhor equilÃ­brio entre precisÃ£o e recall, alÃ©m de maior acurÃ¡cia (0.79).

---

## 6. Modelo Final â€“ Ajuste de HiperparÃ¢metros

### ğŸ”§ RandomizedSearchCV

| precision | recall | f1-score | support |
|-----------|--------|----------|---------|
| 0         | 0.88   | 0.79     | 0.83    | 1030    |
| 1         | 0.55   | 0.71     | 0.62    | 373     |
| **accuracy** |        |          | 0.77    | 1403    |

> Modelo robusto, mas com trade-off entre custo de retenÃ§Ã£o (precisÃ£o baixa) e eficÃ¡cia na detecÃ§Ã£o (recall alto).

### ğŸ” GridSearchCV

> Resultados semelhantes ao RandomizedSearchCV.  
> GridSearch foi descartado por nÃ£o apresentar ganho relevante e ter maior tempo de execuÃ§Ã£o.

### ğŸ” SeleÃ§Ã£o das Melhores Features

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0      | 0.90      | 0.73   | 0.81     | 1030    |
| 1      | 0.51      | 0.78   | 0.62     | 373     |

**AcurÃ¡cia:** 0.74  
**F1 ponderado:** 0.76

ğŸ“Œ O modelo teve melhor desempenho com as 5 melhores features, garantindo alta sensibilidade na classe de interesse.

---

## 7. Teste com Dados de ValidaÃ§Ã£o

### ğŸ¯ Resultados:

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0      | 0.93      | 0.81   | 0.87     | 16      |
| 1      | 0.57      | 0.80   | 0.67     | 5       |

- ğŸ“¦ AcurÃ¡cia: 81%  
- ğŸ“¦ F1 ponderado: 0.82  
- ğŸ” ğŸ”— [Link da matriz de confusÃ£o]  
- ğŸ“„ ğŸ”— [CSV com resultados da validaÃ§Ã£o]

âš ï¸ Amostra pequena (n=21), ainda assim mostra robustez com recall alto na classe 1.

---

## 8. ConclusÃ£o EstratÃ©gica

O modelo final Random Forest com SMOTE atingiu 78% de recall na classe de churn, com bom equilÃ­brio geral.

VariÃ¡veis como contrato mensal, permanÃªncia, gastos diÃ¡rios e tipo de internet (Fibra Ã“ptica) sÃ£o os principais influenciadores do cancelamento.

O modelo pode ser integrado em pipelines de retenÃ§Ã£o e campanhas direcionadas para evitar evasÃµes futuras.

Apesar dos bons resultados, aÃ§Ãµes de retenÃ§Ã£o baseadas nas previsÃµes devem considerar o trade-off entre precisÃ£o e custo operacional.

---

## ğŸ“‚ Recursos Visuais

- ğŸ”— [Matriz de ConfusÃ£o]  
- ğŸ”— [Curva ROC AUC]  
- ğŸ”— [Curva PrecisÃ£o x Recall]  
- ğŸ”— [Features Importances (GrÃ¡fico)]  
- ğŸ”— [Curva de Aprendizado (Overfitting/Underfitting)]


---

Arquitetura_Projeto.md
# ğŸ—ï¸ Arquitetura do Projeto â€“ PrevisÃ£o de EvasÃ£o de Clientes (Churn)

---

## ğŸ“ Estrutura de Pastas e Arquivos

# ğŸ“ Estrutura de DiretÃ³rios do Projeto `churn_prediction_project`

```bash
churn_prediction_project/
â”‚
â”œâ”€â”€ data/                             # Dados utilizados no projeto
â”‚   â”œâ”€â”€ raw/                          # ğŸ“¦ Dados brutos originais
â”‚   â”œâ”€â”€ processed/                    # ğŸ§¹ Dados tratados e codificados
â”‚   â”œâ”€â”€ balanced/                     # âš–ï¸ Dados balanceados (oversampling e undersampling)
â”‚   â””â”€â”€ validation/                   # âœ… Dados de validaÃ§Ã£o final
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ churn_modeling.ipynb          # ğŸ“’ Notebook principal com todo o pipeline de modelagem
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ graphics/                     # ğŸ“Š Imagens: matriz, curvas ROC, precisÃ£o x recall, features
â”‚   â”œâ”€â”€ metrics/                      # ğŸ“‘ RelatÃ³rios em CSV (classification report, cross-validation, etc.)
â”‚   â””â”€â”€ model_test_results/           # ğŸ§ª Resultados do teste com novos dados
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ final_model.pkl               # ğŸ§  Modelo treinado salvo com pipeline
â”‚
â”œâ”€â”€ src/                              # ğŸ“¦ CÃ³digo-fonte modular
â”‚   â”œâ”€â”€ preprocessing.py              # ğŸ”§ FunÃ§Ãµes de tratamento e codificaÃ§Ã£o
â”‚   â”œâ”€â”€ modeling.py                   # ğŸ¤– Treinamento, avaliaÃ§Ã£o e tuning de modelos
â”‚   â””â”€â”€ utils.py                      # ğŸ§° FunÃ§Ãµes auxiliares (plotagem, mÃ©tricas, etc.)
â”‚
â”œâ”€â”€ requirements.txt                  # ğŸ“¦ Lista de dependÃªncias e bibliotecas utilizadas
â”œâ”€â”€ README.md                         # ğŸ—‚ï¸ DocumentaÃ§Ã£o geral e apresentaÃ§Ã£o do projeto
â”œâ”€â”€ Relatorio_Tecnico.md              # ğŸ“˜ RelatÃ³rio tÃ©cnico completo
â””â”€â”€ Arquitetura_Projeto.md            # ğŸ§± Estrutura e organizaÃ§Ã£o do projeto

---

## ğŸ§± Componentes do Projeto

### 1. **Coleta e Leitura dos Dados**
- Fonte: Arquivo CSV local (ou importado via URL)
- Biblioteca: `pandas`

### 2. **Tratamento e Engenharia de Dados**
- RemoÃ§Ã£o de colunas redundantes (ex: `gastos_mensais`)
- CodificaÃ§Ã£o: `OneHotEncoder` (via `pandas.get_dummies`)
- Armazenamento do dataset processado em `/data/processed/`

### 3. **ExploraÃ§Ã£o e VisualizaÃ§Ã£o**
- Bibliotecas: `seaborn`, `matplotlib`
- GrÃ¡ficos:
  - CorrelaÃ§Ã£o
  - Boxplots
  - Tempo de contrato Ã— Cancelamento
  - Total gasto Ã— Cancelamento

### 4. **Balanceamento dos Dados**
- Oversampling: `SMOTE`
- Undersampling: `NearMiss`
- Aplicado dentro de `Pipeline` com `imbpipeline`

### 5. **Modelagem**
- Algoritmos:
  - `DecisionTreeClassifier`
  - `RandomForestClassifier`
- Biblioteca: `sklearn.ensemble`, `sklearn.tree`
- Ajustes: `class_weight=balanced`, `max_depth=10`

### 6. **ValidaÃ§Ã£o e AvaliaÃ§Ã£o**
- SeparaÃ§Ã£o: `train_test_split` (75/25)
- MÃ©tricas:
  - `confusion_matrix`
  - `classification_report`
  - `roc_auc_score`
  - `precision_recall_curve`
- VisualizaÃ§Ãµes:
  - Matriz de confusÃ£o
  - Curva ROC
  - Curva PrecisÃ£o x Recall
  - Learning Curve (`sklearn.model_selection.learning_curve`)

### 7. **Tuning de HiperparÃ¢metros**
- RandomizedSearchCV âœ…
- GridSearchCV (nÃ£o adotado)
- EstratÃ©gia de cross-validation com `StratifiedKFold`
- Armazenamento dos resultados em `/reports/metrics/`

### 8. **ExportaÃ§Ã£o e ProduÃ§Ã£o**
- Modelo salvo via `pickle` (`final_model.pkl`)
- Pipeline salva inclui:
  - PrÃ©-processamento
  - CodificaÃ§Ã£o
  - Modelo
- VariÃ¡veis salvas:
  - `features_names_in_`
  - `pipeline` final

---

## âš™ï¸ Tecnologias Utilizadas

| Categoria                 | Tecnologia / Biblioteca        |
|---------------------------|-------------------------------|
| ManipulaÃ§Ã£o de Dados      | `pandas`, `numpy`             |
| VisualizaÃ§Ã£o              | `matplotlib`, `seaborn`       |
| Modelagem Preditiva       | `sklearn`, `imblearn`         |
| Balanceamento de Dados    | `SMOTE`, `NearMiss`           |
| OtimizaÃ§Ã£o de Modelos     | `GridSearchCV`, `RandomizedSearchCV` |
| MÃ©tricas e AvaliaÃ§Ã£o      | `confusion_matrix`, `roc_auc_score`, `precision_recall_curve` |
| ExportaÃ§Ã£o de Modelo      | `pickle`                      |
| Ambiente de Desenvolvimento | Google Colab / Jupyter Notebook |

---

## ğŸ” PersistÃªncia de Artefatos

- `final_model.pkl` â†’ ContÃ©m modelo, pipeline e colunas
- Dados balanceados e tratados armazenados em CSVs
- MÃ©tricas salvas como CSVs
- GrÃ¡ficos salvos em `/reports/graphics/` com nomes padronizados

---

## ğŸ§ª Teste do Modelo com Dados Finais

- Utilizado conjunto `/data/validation/`
- Resultados armazenados em:
  - Matriz: `/reports/graphics/matriz_validacao.png`
  - CSV: `/reports/model_test_results/teste_validacao.csv`

---

## ğŸ“Œ ObservaÃ§Ãµes Finais

- O pipeline Ã© **100% reprodutÃ­vel** e pode ser reaplicado com novos dados.
- A estrutura de projeto foi pensada para **facilitar reuso, manutenÃ§Ã£o e portabilidade.**
- Modelo encapsula todas as etapas, eliminando necessidade de retratamento fora do pipeline.

---


REQUERIMENTOS

pandas==2.2.2
numpy==1.26.4
matplotlib==3.8.4
seaborn==0.13.2
scikit-learn==1.4.2
imbalanced-learn==0.12.0
pickle-mixin==1.0.2



