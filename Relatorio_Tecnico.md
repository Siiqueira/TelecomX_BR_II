# ğŸ“Š RelatÃ³rio TÃ©cnico â€“ AnÃ¡lise do Modelo de PrevisÃ£o de EvasÃ£o de Clientes (Churn)

---

## ğŸ“Œ SumÃ¡rio

1. [Carregamento e Tratamento dos Dados](#1-carregamento-e-tratamento-dos-dados)
2. [AnÃ¡lise ExploratÃ³ria e CorrelaÃ§Ãµes](#2-anÃ¡lise-exploratÃ³ria-e-correlaÃ§Ãµes)
3. [Modelagem Inicial](#3-modelagem-inicial)
4. [AvaliaÃ§Ã£o dos Modelos](#4-avaliaÃ§Ã£o-dos-modelos)
5. [Balanceamento dos Dados](#5-balanceamento-dos-dados)
6. [Modelo Final â€“ Ajuste de HiperparÃ¢metros](#6-modelo-final--ajuste-de-hiperparÃ¢metros)
7. [Teste com Dados de ValidaÃ§Ã£o](#7-teste-com-dados-de-validaÃ§Ã£o)
8. [ConclusÃ£o EstratÃ©gica](#8-conclusÃ£o-estratÃ©gica)

---

## 1. Carregamento e Tratamento dos Dados

Os dados foram carregados e tratados com as seguintes aÃ§Ãµes:

- RemoÃ§Ã£o de colunas irrelevantes
- TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas com One Hot Encoding
- AnÃ¡lise de proporÃ§Ã£o da variÃ¡vel alvo (target)

### ProporÃ§Ã£o do Target (Cancelamento):

- **NÃ£o Cancelaram (classe 0):** 73%
- **Cancelaram (classe 1):** 27%

ğŸ” *Os dados estÃ£o desbalanceados. Isso pode causar viÃ©s nos modelos preditivos. TÃ©cnicas de oversampling e undersampling foram testadas para mitigar esse problema.*

---

## 2. AnÃ¡lise ExploratÃ³ria e CorrelaÃ§Ãµes

### Principais descobertas:

- **Gastos Mensais** e **Gastos DiÃ¡rios** tÃªm **correlaÃ§Ã£o perfeita**. Decidimos remover `gastos_mensais`.
- Contrato Mensal tem forte correlaÃ§Ã£o com cancelamento (**+40%**).
- Clientes com maior permanÃªncia tÃªm menor chance de cancelar (**correlaÃ§Ã£o negativa de -35%**).
- Fibra Ã“ptica estÃ¡ correlacionada com gastos elevados e maior taxa de churn.
- Clientes com contratos mais curtos tendem a acumular menos gastos e cancelar mais cedo.

ğŸ“ˆ **Links para grÃ¡ficos:**
- [ğŸ”— GrÃ¡fico de CorrelaÃ§Ã£o](https://raw.githubusercontent.com/Siiqueira/TelecomX_BR_II/refs/heads/main/data/results/img/matriz_correlacao.png)
- [ğŸ”— Tempo de Contrato x Cancelamento](https://raw.githubusercontent.com/Siiqueira/TelecomX_BR_II/refs/heads/main/data/results/img/cancelamento_tempo_contrato.png)
- [ğŸ”— Total de Gasto x Cancelamento](https://raw.githubusercontent.com/Siiqueira/TelecomX_BR_II/refs/heads/main/data/results/img/cancelamento_total_gastos.png)

---

## 3. Modelagem Inicial

### SeparaÃ§Ã£o dos dados:

- **Dados de treino:** (5608, 26)
- **Dados de teste:** (1403, 26)

### Modelos testados:

1. **Decision Tree Classifier**
```python
DecisionTreeClassifier(
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
```

## 4. AvaliaÃ§Ã£o dos Modelos

### ğŸ”¢ MÃ©tricas Comparativas

| Modelo         | AUC  | Recall (Classe 1) | F1 (Classe 1) | Accuracy |
|----------------|------|-------------------|---------------|----------|
| Decision Tree  | 0.73 | 0.69              | 0.57          | 0.72     |
| Random Forest  | 0.82 | 0.71              | 0.61          | 0.76     |

### ğŸ“‰ Matriz de ConfusÃ£o

ğŸ”— [Matriz de confusÃ£o comparativo](https://raw.githubusercontent.com/Siiqueira/TelecomX_BR_II/refs/heads/main/data/results/img/matriz_confusao_comparacao.png)

> Random Forest foi superior em quase todas as mÃ©tricas, principalmente na identificaÃ§Ã£o correta de clientes que nÃ£o cancelam (classe 0).  
> A classe 1 (cancelamento) ainda apresenta desafios.

### ğŸ“ˆ Curva ROC AUC

ğŸ”— [GrÃ¡fico Curva Roc Comparativo]

- Decision Tree: AUC = 0.73  
- Random Forest: AUC = 0.82

### ğŸ“ˆ Curva PrecisÃ£o x Recall

ğŸ”— [GrÃ¡fico curva PR Comparativo](https://raw.githubusercontent.com/Siiqueira/TelecomX_BR_II/refs/heads/main/data/results/img/curva_pr_comparacao.png)

- Decision Tree: Avg. Precision = 0.44  
- Random Forest: Avg. Precision = 0.59

### ğŸ“„ Classification Report

ğŸ”— [Link para CSV com os relatÃ³rios]

> Random Forest teve melhor desempenho para a classe de interesse (churn).  
> F1-Score e recall da classe 1 foram superiores ao Decision Tree.

### ğŸ” ValidaÃ§Ã£o Cruzada

ğŸ”— [Link para CSV]

> Resultados mais estÃ¡veis e consistentes com Random Forest.  
> Menor variÃ¢ncia e melhor generalizaÃ§Ã£o.

---

## 5. Balanceamento dos Dados

**TÃ©cnicas utilizadas:**

- Oversampling (SMOTE) âœ… escolhido  
- Undersampling (NearMiss)

ğŸ“„ ğŸ”— [CSV com resultados]

**Escolha: Oversampling com SMOTE**  
âœ… Apresentou melhor equilÃ­brio entre precisÃ£o e recall, alÃ©m de maior acurÃ¡cia (0.79).

---

## 6. Modelo Final â€“ Ajuste de HiperparÃ¢metros

### ğŸ”§ RandomizedSearchCV

| precision | recall | f1-score | support |
|-----------|--------|----------|---------|
| 0         | 0.88   | 0.79     | 0.83    | 1030    |
| 1         | 0.55   | 0.71     | 0.62    | 373     |
| **accuracy** |        |          | 0.77    | 1403    |

> Modelo robusto, mas com trade-off entre custo de retenÃ§Ã£o (precisÃ£o baixa) e eficÃ¡cia na detecÃ§Ã£o (recall alto).

### ğŸ” GridSearchCV

> Resultados semelhantes ao RandomizedSearchCV.  
> GridSearch foi descartado por nÃ£o apresentar ganho relevante e ter maior tempo de execuÃ§Ã£o.

### ğŸ” SeleÃ§Ã£o das Melhores Features

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0      | 0.90      | 0.73   | 0.81     | 1030    |
| 1      | 0.51      | 0.78   | 0.62     | 373     |

**AcurÃ¡cia:** 0.74  
**F1 ponderado:** 0.76

ğŸ“Œ O modelo teve melhor desempenho com as 5 melhores features, garantindo alta sensibilidade na classe de interesse.

---

## 7. Teste com Dados de ValidaÃ§Ã£o

### ğŸ¯ Resultados:

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0      | 0.93      | 0.81   | 0.87     | 16      |
| 1      | 0.57      | 0.80   | 0.67     | 5       |

- ğŸ“¦ AcurÃ¡cia: 81%  
- ğŸ“¦ F1 ponderado: 0.82  
- ğŸ” ğŸ”— [Link da matriz de confusÃ£o]  
- ğŸ“„ ğŸ”— [CSV com resultados da validaÃ§Ã£o]

âš ï¸ Amostra pequena (n=21), ainda assim mostra robustez com recall alto na classe 1.

---

## 8. ConclusÃ£o EstratÃ©gica

O modelo final Random Forest com SMOTE atingiu 78% de recall na classe de churn, com bom equilÃ­brio geral.

VariÃ¡veis como contrato mensal, permanÃªncia, gastos diÃ¡rios e tipo de internet (Fibra Ã“ptica) sÃ£o os principais influenciadores do cancelamento.

O modelo pode ser integrado em pipelines de retenÃ§Ã£o e campanhas direcionadas para evitar evasÃµes futuras.

Apesar dos bons resultados, aÃ§Ãµes de retenÃ§Ã£o baseadas nas previsÃµes devem considerar o trade-off entre precisÃ£o e custo operacional.

---

## ğŸ“‚ Recursos Visuais

- ğŸ”— [Matriz de ConfusÃ£o]  
- ğŸ”— [Curva ROC AUC]  
- ğŸ”— [Curva PrecisÃ£o x Recall]  
- ğŸ”— [Features Importances (GrÃ¡fico)]  
- ğŸ”— [Curva de Aprendizado (Overfitting/Underfitting)]


---

